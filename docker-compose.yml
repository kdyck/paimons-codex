version: '3.8'

services:
  # Oracle Database 23ai
  oracle-db:
    image: container-registry.oracle.com/database/free:23.5.0.0-lite
    container_name: paimons-oracle
    environment:
      - ORACLE_PWD=OraclePassword123
      - ORACLE_CHARACTERSET=AL32UTF8
    ports:
      - "1521:1521"
    volumes:
      - oracle_data:/opt/oracle/oradata
      - ./config/oracle:/opt/oracle/scripts/startup
    healthcheck:
      test: ["CMD-SHELL", "echo 'SELECT 1 FROM DUAL;' | sqlplus -S sys/OraclePassword123@//localhost:1521/FREEPDB1 as sysdba | grep -q '^1$'"]
      interval: 15s
      timeout: 5s
      retries: 10
      start_period: 120s
    restart: unless-stopped

  # FastAPI Backend
  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    container_name: paimons-api
    depends_on:
      minio: {}
      ollama: {}
      stable-diffusion: {}
    environment:
      - ORACLE_USER=paimons_user
      - ORACLE_PASSWORD=password123
      - ORACLE_DSN=oracle-db:1521/FREEPDB1
      - PYTHONPATH=/app
      - ORACLE_SKIP=false
      - ORACLE_LIB_DIR=/opt/oracle/instantclient_21_13
      - MINIO_ENDPOINT=10.89.0.3:9000
      - MINIO_ACCESS_KEY=paimons
      - MINIO_SECRET_KEY=paimons123
      - MINIO_BUCKET_NAME=codex
      - OLLAMA_BASE_URL=http://10.89.0.4:11434
      - SD_API_URL=http://10.89.0.5:7860
    ports:
      - "127.0.0.1:8000:8000"
    volumes:
      - ./api:/app
      - ./dal:/app/dal
    restart: unless-stopped
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload

  # React Frontend
  ui:
    build:
      context: ./ui
      dockerfile: Dockerfile
    container_name: paimons-ui
    environment:
      - REACT_APP_API_URL=http://localhost:8000
      - BROWSER=none
      - FAST_REFRESH=false
    ports:
      - "127.0.0.1:3000:3000"
    volumes:
      - ./ui:/app
      - /app/node_modules
    restart: unless-stopped
    command: npm start

  # Caddy Reverse Proxy
  caddy:
    image: caddy:2.7-alpine
    container_name: paimons-caddy
    ports:
      - "8080:80"
      - "8443:443"
    volumes:
      - ./config/Caddyfile:/etc/caddy/Caddyfile
      - caddy_data:/data
      - caddy_config:/config
    depends_on:
      - api
      - ui
    restart: unless-stopped


  # MinIO Object Storage
  minio:
    image: minio/minio:latest
    container_name: paimons-minio
    environment:
      - MINIO_ROOT_USER=paimons
      - MINIO_ROOT_PASSWORD=paimons123
      - MINIO_CONSOLE_ADDRESS=:9001
    ports:
      - "127.0.0.1:9000:9000"  # MinIO API
      - "127.0.0.1:9001:9001"  # MinIO Console (Web UI)
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # Ollama LLM Server  
  ollama:
    image: ollama/ollama:latest
    container_name: paimons-ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      - OLLAMA_NUM_CTX=4096
      - OLLAMA_KEEP_ALIVE=10m
      - OLLAMA_NUM_THREAD=8
    ports:
      - "127.0.0.1:11434:11434"
    volumes:
      - ollama_models:/root/.ollama
    devices:
      - nvidia.com/gpu=all
    restart: unless-stopped

  # Stable Diffusion Service  
  stable-diffusion:
    build:
      context: ./sd-service
      dockerfile: Dockerfile
    container_name: paimons-sd
    environment:
      - PYTHONUNBUFFERED=1
      # NVMe SSD paths for maximum performance
      - HF_HOME=/nvme-models
      - CUDA_VISIBLE_DEVICES=0
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
      - TORCH_CUDNN_V8_API_ENABLED=1
      # SSD-optimized cache directories 
      - TRANSFORMERS_CACHE=/nvme-models/transformers
      - HF_DATASETS_CACHE=/nvme-models/datasets
      - DIFFUSERS_CACHE=/nvme-models/diffusers
      - HF_MODELS_CACHE=/nvme-models/hub
      # Output directory on fast SSD
      - SD_OUTPUT_DIR=/nvme-outputs
      - SD_TEMP_DIR=/nvme-temp
      # Enable SSD optimizations
      - PYTORCH_JIT_USE_NNC_NOT_NVFUSER=1
    ports:
      - "127.0.0.1:7860:7860"
    volumes:
      # Map to NVMe SSD drives D: and E: via Windows paths
      - /mnt/d/sd-models:/nvme-models
      - /mnt/d/sd-outputs:/nvme-outputs  
      - /mnt/d/sd-temp:/nvme-temp
      - ./lora-training:/lora-training
      - ./training-data:/training-data
      - ./sd-service:/app
    devices:
      - nvidia.com/gpu=all
    # Increase shared memory for large batch processing  
    shm_size: 8gb
    # Memory limits for your 128GB setup
    mem_limit: 32g
    memswap_limit: 32g
    restart: unless-stopped

volumes:
  oracle_data:
  caddy_data:
  caddy_config:
  minio_data:
  ollama_models:
  # sd_models: # Removed - now using direct NVMe SSD mapping